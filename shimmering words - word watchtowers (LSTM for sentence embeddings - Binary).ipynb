{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfcace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "import json\n",
    "import collections\n",
    "import operator\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb384a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file.columns, train_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_length = 6\n",
    "new_label = []\n",
    "for each in train_file['label']:\n",
    "    temp = str(each)\n",
    "    if len(temp) != max_label_length:\n",
    "        zeros = max_label_length - len(str(each))\n",
    "        res = temp.rjust(zeros + len(temp), '0')\n",
    "        new_label.append(res)\n",
    "    else:\n",
    "        new_label.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file['label'] = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71521365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = train_file.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toxic = train_file[(train_file.label != '000000')].reset_index(drop = True)\n",
    "non_toxic = train_file[(train_file.label == '000000')].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toxic.shape, non_toxic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb32e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic_labels = [0] * non_toxic.shape[0]\n",
    "toxic_labels = [1] * all_toxic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic['label'] = non_toxic_labels\n",
    "all_toxic['label'] = toxic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74177347",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic.head(4), all_toxic.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a63901",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_frame = pd.concat([non_toxic, all_toxic], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, non_train = train_test_split(whole_frame, test_size=0.1, random_state=42, stratify = whole_frame['label'], shuffle = True)\n",
    "val, test = train_test_split(non_train, test_size=0.1, random_state=42, stratify = non_train['label'], shuffle = True)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db326ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "del non_toxic\n",
    "del all_toxic\n",
    "\n",
    "x_train = train['comment_text'].reset_index(drop = True)\n",
    "y_train = train['label'].reset_index(drop = True)\n",
    "\n",
    "x_val = val['comment_text'].reset_index(drop = True)\n",
    "y_val = val['label'].reset_index(drop = True)\n",
    "\n",
    "x_test = test['comment_text'].reset_index(drop = True)\n",
    "y_test = test['label'].reset_index(drop = True)\n",
    "\n",
    "\n",
    "del train\n",
    "del val\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599543a",
   "metadata": {},
   "source": [
    "#### Split the comment and get the vectors for words\n",
    "#### if the word is OOV, simply skip, and in process if list is empty then append 0\n",
    "#### if sentence vectors by average: simple take mean\n",
    "#### else return all vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc02917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vectors(datapoint, vector_type):\n",
    "    words = datapoint.split(' ')\n",
    "    word_vectors = []\n",
    "    for each in words:\n",
    "        try:\n",
    "            word_vectors.append(fasttext_vectors[each])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    word_vectors = np.array(word_vectors)\n",
    "    \n",
    "    if vector_type == 'sent':\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.mean(word_vectors, axis = 0)\n",
    "    else:\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0, 0\n",
    "        else:\n",
    "            return word_vectors, len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f79c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde84f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_vector = x_train.apply(sentence_vectors, vector_type = 'word')\n",
    "val_word_vector = x_val.apply(sentence_vectors, vector_type = 'word')\n",
    "test_word_vector = x_test.apply(sentence_vectors, vector_type = 'word')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210bebb",
   "metadata": {},
   "source": [
    "#### get max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ec8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vts_and_lgts(train_word_vector):\n",
    "    lengths = []\n",
    "    vectors = []\n",
    "    for each in range(train_word_vector.shape[0]):\n",
    "        lengths.append(train_word_vector.iloc[each][1])\n",
    "        vectors.append(train_word_vector.iloc[each][0])\n",
    "    return vectors, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train, lengths_train = get_vts_and_lgts(train_word_vector)\n",
    "vectors_val, lengths_val = get_vts_and_lgts(val_word_vector)\n",
    "vectors_test, _ = get_vts_and_lgts(test_word_vector)\n",
    "del train_word_vector, val_word_vector, test_word_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb800f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(max(lengths_train), max(lengths_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91faafa",
   "metadata": {},
   "source": [
    "#### Get indices where 0 is returned and discard them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_zerovectors(train_sentence_vector):\n",
    "    remove_indices = []\n",
    "    for index, vector in enumerate(train_sentence_vector):\n",
    "        if vector.shape == ():\n",
    "            remove_indices.append(index)\n",
    "    return remove_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_remove_indices = get_index_zerovectors(vectors_train)\n",
    "val_remove_indices = get_index_zerovectors(vectors_val)\n",
    "test_remove_indices = get_index_zerovectors(vectors_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5970d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train = [i for j, i in enumerate(vectors_train) if j not in train_remove_indices]\n",
    "y_train = [i for j, i in enumerate(y_train) if j not in train_remove_indices]\n",
    "\n",
    "vectors_val = [i for j, i in enumerate(vectors_val) if j not in val_remove_indices]\n",
    "y_val = [i for j, i in enumerate(y_val) if j not in val_remove_indices]\n",
    "\n",
    "vectors_test = [i for j, i in enumerate(vectors_test) if j not in test_remove_indices]\n",
    "y_test = [i for j, i in enumerate(y_test) if j not in test_remove_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dbfe69",
   "metadata": {},
   "source": [
    "#### Make lengths of all comments same as max_len with appending 0.0 at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train = tf.keras.utils.pad_sequences(\n",
    "    vectors_train,\n",
    "    maxlen=max_len,\n",
    "    dtype='int32',\n",
    "    padding='pre',\n",
    "    truncating='pre',\n",
    "    value=0.0\n",
    ")\n",
    "vectors_val = tf.keras.utils.pad_sequences(\n",
    "    vectors_val,\n",
    "    maxlen=max_len,\n",
    "    dtype='int32',\n",
    "    padding='pre',\n",
    "    truncating='pre',\n",
    "    value=0.0\n",
    ")\n",
    "vectors_test = tf.keras.utils.pad_sequences(\n",
    "    vectors_test,\n",
    "    maxlen=max_len,\n",
    "    dtype='int32',\n",
    "    padding='pre',\n",
    "    truncating='pre',\n",
    "    value=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train.shape, y_train.shape, vectors_val.shape, y_val.shape, vectors_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn():\n",
    "    inputs = tf.keras.Input(shape = (1250, 300))\n",
    "    x = tf.keras.layers.SimpleRNN(8, activation = 'tanh')(inputs)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.8),\n",
    "      \n",
    "]\n",
    "\n",
    "model_rnn = rnn()\n",
    "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "model_rnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rnn = model_rnn.fit(x = vectors_train, y = y_train, validation_data=(vectors_val, y_val), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rnn = model_rnn.predict(vectors_test)\n",
    "conf_mat = confusion_matrix(y_test, preds_rnn)\n",
    "    \n",
    "print(conf_mat)\n",
    "print('f1 score',f1_score(y_test, preds_rnn, average='weighted', zero_division = 1))\n",
    "print('recall',recall_score(y_test, preds_rnn, average='weighted', zero_division = 1))\n",
    "print('precision',precision_score(y_test, preds_rnn, average='weighted', zero_division =1))\n",
    "print('accuracy',accuracy_score(y_test, preds_rnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2c71e",
   "metadata": {},
   "source": [
    "#### Bahdanau Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90205be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, inputs_0, inputs_1):\n",
    "        super().__init__()\n",
    "        self.W = self.add_weight(name = 'attention_weight', shape = (inputs_1, 1),\n",
    "                             initializer = 'random_normal', trainable = True)\n",
    "        self.b = self.add_weight(name = 'attention_bias', shape = (inputs_0, 1),\n",
    "                             initializer = 'zeros', trainable = True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        e = tf.math.tanh(tf.matmul(inputs, self.W) + self.b)\n",
    "        e = tf.squeeze(e, axis=-1, name='squeeze')\n",
    "        alpha = tf.nn.softmax(e)\n",
    "        alpha = tf.expand_dims(alpha, axis = -1)\n",
    "        context = inputs * alpha\n",
    "        context = tf.math.reduce_sum(context, axis = -1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44061f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_attention():\n",
    "    inputs = tf.keras.Input(shape = (1250, 300))\n",
    "    x = tf.keras.layers.SimpleRNN(8, return_sequences = True, activation = 'tanh')(inputs)\n",
    "    x = attention(x.shape[1], x.shape[2])(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.8),\n",
    "      \n",
    "]\n",
    "\n",
    "model_attention = rnn_attention()\n",
    "model_attention.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "model_attention.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a54172",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rnnatten = model_attention.fit(x = vectors_train, y = y_train, validation_data=(vectors_val, y_val), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_attn = model_attention.predict(vectors_test)\n",
    "conf_mat = confusion_matrix(y_test, preds_rnn)\n",
    "    \n",
    "print(conf_mat)\n",
    "print('f1 score',f1_score(y_test, preds_attn, average='weighted', zero_division = 1))\n",
    "print('recall',recall_score(y_test, preds_attn, average='weighted', zero_division = 1))\n",
    "print('precision',precision_score(y_test, preds_attn, average='weighted', zero_division =1))\n",
    "print('accuracy',accuracy_score(y_test, preds_attn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8398621",
   "metadata": {},
   "source": [
    "#### weighted attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d52f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wtgd_attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attn_weights = tf.nn.softmax(self.V(score), axis = 1)\n",
    "        context_vector = tf.math.reduce_sum(attn_weights * features, axis = 1)\n",
    "        return context_vector, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm_attention():\n",
    "    inputs = tf.keras.Input(shape = (1250, 300))\n",
    "    lstm, f_h, f_c, b_h, b_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8, return_sequences = True, return_state=True, activation = 'tanh'))(inputs)\n",
    "    state_h = tf.keras.layers.Concatenate()([f_h, b_h])\n",
    "    state_c = tf.keras.layers.Concatenate()([f_c, b_c])\n",
    "    vector, weights = wtgd_attention(10)(lstm, state_h)\n",
    "    outputs = tf.keras.layers.Dense(1)(vector)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.8),\n",
    "      \n",
    "]\n",
    "\n",
    "bilstm_attention = bilstm_attention()\n",
    "bilstm_attention.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "bilstm_attention.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bilstm = bilstm_attention.fit(x = vectors_train, y = y_train, validation_data=(vectors_val, y_val), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfe184",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_biattn = bilstm_attention.predict(vectors_test)\n",
    "conf_mat = confusion_matrix(y_test, preds_rnn)\n",
    "    \n",
    "print(conf_mat)\n",
    "print('f1 score',f1_score(y_test, preds_biattn, average='weighted', zero_division = 1))\n",
    "print('recall',recall_score(y_test, preds_biattn, average='weighted', zero_division = 1))\n",
    "print('precision',precision_score(y_test, preds_biattn, average='weighted', zero_division =1))\n",
    "print('accuracy',accuracy_score(y_test, preds_biattn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839a7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
