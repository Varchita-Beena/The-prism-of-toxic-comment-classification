{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfcace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb384a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file.columns, train_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_length = 6\n",
    "new_label = []\n",
    "for each in train_file['label']:\n",
    "    temp = str(each)\n",
    "    if len(temp) != max_label_length:\n",
    "        zeros = max_label_length - len(str(each))\n",
    "        res = temp.rjust(zeros + len(temp), '0')\n",
    "        new_label.append(res)\n",
    "    else:\n",
    "        new_label.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file['label'] = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71521365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = train_file.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ed932",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_label = train_file['label'].value_counts()\n",
    "value_counts_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_one_dp = ['110110', '110101']\n",
    "inds = train_file[ (train_file['label'] == '110110') ].index\n",
    "train_file.drop(inds , inplace=True)\n",
    "train_file.shape\n",
    "\n",
    "inds = train_file[ (train_file['label'] == '110101') ].index\n",
    "train_file.drop(inds , inplace=True)\n",
    "train_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_file, test_size=0.1, random_state=42, stratify = train_file['label'], shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train = train['comment_text'].reset_index(drop = True)\n",
    "y_train = train['label'].reset_index(drop = True)\n",
    "\n",
    "x_val = val['comment_text'].reset_index(drop = True)\n",
    "y_val = val['label'].reset_index(drop = True)\n",
    "\n",
    "\n",
    "del train\n",
    "del val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475f3b5",
   "metadata": {},
   "source": [
    "#### Split the comment and get the vectors for words\n",
    "#### if the word is OOV, simply skip, and in process if list is empty then append 0\n",
    "#### if sentence vectors by average: simple take mean\n",
    "#### else return all vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc02917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vectors(datapoint, vector_type):\n",
    "    words = datapoint.split(' ')\n",
    "    word_vectors = []\n",
    "    for each in words:\n",
    "        try:\n",
    "            word_vectors.append(fasttext_vectors[each])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    word_vectors = np.array(word_vectors)\n",
    "    \n",
    "    if vector_type == 'sent':\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.mean(word_vectors, axis = 0)\n",
    "    else:\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0, 0\n",
    "        else:\n",
    "            return word_vectors, len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f79c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde84f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_vector = x_train.apply(sentence_vectors, vector_type = 'word')\n",
    "val_word_vector = x_val.apply(sentence_vectors, vector_type = 'word')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ec8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vts_and_lgts(train_word_vector):\n",
    "    lengths = []\n",
    "    vectors = []\n",
    "    for each in range(train_word_vector.shape[0]):\n",
    "        lengths.append(train_word_vector.iloc[each][1])\n",
    "        vectors.append(train_word_vector.iloc[each][0])\n",
    "    return vectors, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train, lengths_train = get_vts_and_lgts(train_word_vector)\n",
    "vectors_val, lengths_val = get_vts_and_lgts(val_word_vector)\n",
    "\n",
    "del train_word_vector, val_word_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb800f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(max(lengths_train), max(lengths_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c558a",
   "metadata": {},
   "source": [
    "#### Get indices where 0 is returned and discard them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e29db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_zerovectors(train_sentence_vector):\n",
    "    remove_indices = []\n",
    "    for index, vector in enumerate(train_sentence_vector):\n",
    "        if vector.shape == ():\n",
    "            remove_indices.append(index)\n",
    "    return remove_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_remove_indices = get_index_zerovectors(vectors_train)\n",
    "val_remove_indices = get_index_zerovectors(vectors_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5970d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train = [i for j, i in enumerate(vectors_train) if j not in train_remove_indices]\n",
    "y_train = [i for j, i in enumerate(y_train) if j not in train_remove_indices]\n",
    "\n",
    "vectors_val = [i for j, i in enumerate(vectors_val) if j not in val_remove_indices]\n",
    "y_val = [i for j, i in enumerate(y_val) if j not in val_remove_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d054da",
   "metadata": {},
   "source": [
    "#### Make lengths of all comments same as max_len with appending 0.0 at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train = tf.keras.utils.pad_sequences(\n",
    "    vectors_train,\n",
    "    maxlen=max_len,\n",
    "    dtype='int32',\n",
    "    padding='pre',\n",
    "    truncating='pre',\n",
    "    value=0.0\n",
    ")\n",
    "vectors_val = tf.keras.utils.pad_sequences(\n",
    "    vectors_val,\n",
    "    maxlen=max_len,\n",
    "    dtype='int32',\n",
    "    padding='pre',\n",
    "    truncating='pre',\n",
    "    value=0.0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(y):\n",
    "    Y_ = []\n",
    "    for each in y:\n",
    "        a = []\n",
    "        temp = list(each)\n",
    "        for every in temp:\n",
    "            a.append(int(every))\n",
    "        np.array(a)\n",
    "        Y_.append(a)    \n",
    "    return np.array(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f75755",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = string_to_array(y_train)\n",
    "Y_val = string_to_array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train.shape, Y_train.shape, vectors_val.shape, Y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn():\n",
    "    inputs = tf.keras.Input(shape = (1250, 300))\n",
    "    x = tf.keras.layers.SimpleRNN(16, activation = 'tanh')(inputs)\n",
    "    outputs = tf.keras.layers.Dense(6, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.8),\n",
    "]\n",
    "\n",
    "model_rnn = rnn()\n",
    "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "model_rnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a340576",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rnn = model_rnn.fit(x = vectors_train, y = Y_train, validation_data=(vectors_val, Y_val), epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799025b2",
   "metadata": {},
   "source": [
    "#### Get predictions, and where the value is >threshold change to 1 else 0\n",
    "#### We have 6 classes. In multi-label classification - classes are not mutually exclusive\n",
    "#### calculate precision, recall and f1_score for individual classes\n",
    "#### How our model is performing overall -> take the average all precision, recall, f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec42aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rnn = model_rnn.predict(vectors_val)\n",
    "preds_rnn = np.where(preds_rnn > 0.7, 1, 0)\n",
    "\n",
    "p_avg, r_avg, f1_avg = 0,0,0\n",
    "for i in range(6):\n",
    "    real = Y_val[0:, i]\n",
    "    reel = preds_rnn[0:, i]\n",
    "    conf_mat = confusion_matrix(real, reel)\n",
    "\n",
    "    print(conf_mat)\n",
    "    p = precision_score(real, reel)\n",
    "    r = recall_score(real, reel)\n",
    "    f1 = f1_score(real, reel)\n",
    "\n",
    "    print('p---', p)\n",
    "    print('r---', r)\n",
    "    print('f1---', f1)\n",
    "\n",
    "    p_avg += p\n",
    "    r_avg += r\n",
    "    f1_avg += f1\n",
    "\n",
    "    print('************************')\n",
    "print(p_avg / 6, r_avg /6, f1_avg / 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8fb65",
   "metadata": {},
   "source": [
    "#### Bahdanau Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90205be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, inputs_0, inputs_1):\n",
    "        super().__init__()\n",
    "        self.W = self.add_weight(name = 'attention_weight', shape = (inputs_1, 1),\n",
    "                             initializer = 'random_normal', trainable = True)\n",
    "        self.b = self.add_weight(name = 'attention_bias', shape = (inputs_0, 1),\n",
    "                             initializer = 'zeros', trainable = True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        e = tf.math.tanh(tf.matmul(inputs, self.W) + self.b)\n",
    "        e = tf.squeeze(e, axis=-1, name='squeeze')\n",
    "        alpha = tf.nn.softmax(e)\n",
    "        alpha = tf.expand_dims(alpha, axis = -1)\n",
    "        context = inputs * alpha\n",
    "        context = tf.math.reduce_sum(context, axis = -1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44061f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_attention():\n",
    "    inputs = tf.keras.Input(shape = (1250, 300))\n",
    "    x = tf.keras.layers.SimpleRNN(8, return_sequences = True, activation = 'tanh')(inputs)\n",
    "    x = attention(x.shape[1], x.shape[2])(x)\n",
    "    outputs = tf.keras.layers.Dense(6, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.8),\n",
    "      \n",
    "]\n",
    "\n",
    "model_attention = rnn_attention()\n",
    "model_attention.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "model_attention.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a54172",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rnnatten = model_attention.fit(x = vectors_train, y = y_train, validation_data=(vectors_val, y_val), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_attn = model_attention.predict(vectors_val)\n",
    "preds_attn = np.where(preds_attn > 0.7, 1, 0)\n",
    "\n",
    "p_avg, r_avg, f1_avg = 0,0,0\n",
    "for i in range(6):\n",
    "    real = Y_val[0:, i]\n",
    "    reel = preds_attn[0:, i]\n",
    "    conf_mat = confusion_matrix(real, reel)\n",
    "\n",
    "    print(conf_mat)\n",
    "    p = precision_score(real, reel)\n",
    "    r = recall_score(real, reel)\n",
    "    f1 = f1_score(real, reel)\n",
    "\n",
    "    print('p---', p)\n",
    "    print('r---', r)\n",
    "    print('f1---', f1)\n",
    "\n",
    "    p_avg += p\n",
    "    r_avg += r\n",
    "    f1_avg += f1\n",
    "\n",
    "    print('************************')\n",
    "print(p_avg / 6, r_avg /6, f1_avg / 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f6315",
   "metadata": {},
   "source": [
    "#### Weighted attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d52f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wtgd_attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attn_weights = tf.nn.softmax(self.V(score), axis = 1)\n",
    "        context_vector = tf.math.reduce_sum(attn_weights * features, axis = 1)\n",
    "        return context_vector, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm_attention():\n",
    "    inputs = tf.keras.Input(shape = (1250, 300))\n",
    "    lstm, f_h, f_c, b_h, b_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8, return_sequences = True, return_state=True, activation = 'tanh'))(inputs)\n",
    "    state_h = tf.keras.layers.Concatenate()([f_h, b_h])\n",
    "    state_c = tf.keras.layers.Concatenate()([f_c, b_c])\n",
    "    vector, weights = wtgd_attention(10)(lstm, state_h)\n",
    "    outputs = tf.keras.layers.Dense(6, activation = 'sigmoid')(vector)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.8),\n",
    "      \n",
    "]\n",
    "\n",
    "bilstm_attention = bilstm_attention()\n",
    "bilstm_attention.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "bilstm_attention.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bilstm = bilstm_attention.fit(x = vectors_train, y = y_train, validation_data=(vectors_val, y_val), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfe184",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_biattn = bilstm_attention.predict(vectors_val)\n",
    "preds_biattn = np.where(preds_biattn > 0.7, 1, 0)\n",
    "\n",
    "p_avg, r_avg, f1_avg = 0,0,0\n",
    "for i in range(6):\n",
    "    real = Y_val[0:, i]\n",
    "    reel = preds_biattn[0:, i]\n",
    "    conf_mat = confusion_matrix(real, reel)\n",
    "\n",
    "    print(conf_mat)\n",
    "    p = precision_score(real, reel)\n",
    "    r = recall_score(real, reel)\n",
    "    f1 = f1_score(real, reel)\n",
    "\n",
    "    print('p---', p)\n",
    "    print('r---', r)\n",
    "    print('f1---', f1)\n",
    "\n",
    "    p_avg += p\n",
    "    r_avg += r\n",
    "    f1_avg += f1\n",
    "\n",
    "    print('************************')\n",
    "print(p_avg / 6, r_avg /6, f1_avg / 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839a7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
