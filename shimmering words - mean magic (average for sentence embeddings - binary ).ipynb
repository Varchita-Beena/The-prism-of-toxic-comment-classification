{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cfcace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import collections\n",
    "import operator\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb384a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b6a462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "        'identity_hate', 'label'],\n",
       "       dtype='object'),\n",
       " (159513, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file.columns, train_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b56d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_length = 6\n",
    "new_label = []\n",
    "for each in train_file['label']:\n",
    "    temp = str(each)\n",
    "    if len(temp) != max_label_length:\n",
    "        zeros = max_label_length - len(str(each))\n",
    "        res = temp.rjust(zeros + len(temp), '0')\n",
    "        new_label.append(res)\n",
    "    else:\n",
    "        new_label.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea1ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file['label'] = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71521365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = train_file.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46cd090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toxic = train_file[(train_file.label != '000000')].reset_index(drop = True)\n",
    "non_toxic = train_file[(train_file.label == '000000')].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b490b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16225, 2), (143288, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_toxic.shape, non_toxic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb32e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6363e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic_labels = [0] * non_toxic.shape[0]\n",
    "toxic_labels = [1] * all_toxic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b9fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic['label'] = non_toxic_labels\n",
    "all_toxic['label'] = toxic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74177347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                        comment_text  label\n",
       " 0  explanation edits made username hardcore metal...      0\n",
       " 1  aww matches background colour seemingly stuck ...      0\n",
       " 2  hey man really trying edit war guy constantly ...      0\n",
       " 3  make real suggestions improvement wondered sec...      0,\n",
       "                                         comment_text  label\n",
       " 0                        cocksucker piss around work      1\n",
       " 1  hey talk exclusive group wp talibans good dest...      1\n",
       " 2            bye look come think comming back tosser      1\n",
       " 3  gay antisemmitian archangel white tiger meow g...      1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_toxic.head(4), all_toxic.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a63901",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_frame = pd.concat([non_toxic, all_toxic], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc9d929a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143561, 2), (14356, 2), (1596, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, non_train = train_test_split(whole_frame, test_size=0.1, random_state=42, stratify = whole_frame['label'], shuffle = True)\n",
    "val, test = train_test_split(non_train, test_size=0.1, random_state=42, stratify = non_train['label'], shuffle = True)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db326ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "del non_toxic\n",
    "del all_toxic\n",
    "\n",
    "x_train = train['comment_text'].reset_index(drop = True)\n",
    "y_train = train['label'].reset_index(drop = True)\n",
    "\n",
    "x_val = val['comment_text'].reset_index(drop = True)\n",
    "y_val = val['label'].reset_index(drop = True)\n",
    "\n",
    "x_test = test['comment_text'].reset_index(drop = True)\n",
    "y_test = test['label'].reset_index(drop = True)\n",
    "\n",
    "\n",
    "del train\n",
    "del val\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66f79c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432c593",
   "metadata": {},
   "source": [
    "#### download the desired model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bde84f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39cc55",
   "metadata": {},
   "source": [
    "#### Split the sentence, get embedding for every word, if its OOV simply skip.\n",
    "#### Lastly take the average of all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fc02917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vectors(datapoint, vector_type):\n",
    "    words = datapoint.split(' ')\n",
    "    word_vectors = []\n",
    "    for each in words:\n",
    "        try:\n",
    "            word_vectors.append(fasttext_vectors[each])\n",
    "        except KeyError:\n",
    "            #if OOV then skip\n",
    "            pass\n",
    "    #take average\n",
    "    word_vectors = np.array(word_vectors)\n",
    "    \n",
    "    #if while skipping as words are OOV\n",
    "    #the list is empty then return 0\n",
    "    if vector_type == 'sent':\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.mean(word_vectors, axis = 0)\n",
    "    else:\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0, 0\n",
    "        else:\n",
    "            return word_vectors, len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0a9e0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varchitalalwani/miniconda3/envs/TOXIC_COMMENTS/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "train_sentence_vector = x_train.apply(sentence_vectors, vector_type = 'sent')\n",
    "val_sentence_vector = x_val.apply(sentence_vectors, vector_type = 'sent')\n",
    "test_sentence_vector = x_test.apply(sentence_vectors, vector_type = 'sent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e24bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143561,), (143561,), (14356,), (14356,), (1596,), (1596,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentence_vector.shape, y_train.shape, val_sentence_vector.shape, y_val.shape, test_sentence_vector.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c7b0a",
   "metadata": {},
   "source": [
    "#### sentence_vectors returned 0 for the empty sentences\n",
    "#### simply delete those inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d7f4074",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_index_zerovectors(train_sentence_vector):\n",
    "    remove_indices = []\n",
    "    for index, vector in enumerate(train_sentence_vector):\n",
    "        if vector.shape == ():\n",
    "            remove_indices.append(index)\n",
    "    return remove_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d68e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_remove_indices = get_index_zerovectors(train_sentence_vector)\n",
    "val_remove_indices = get_index_zerovectors(val_sentence_vector)\n",
    "test_remove_indices = get_index_zerovectors(test_sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c02929d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_vector = [i for j, i in enumerate(train_sentence_vector) if j not in train_remove_indices]\n",
    "y_train = [i for j, i in enumerate(y_train) if j not in train_remove_indices]\n",
    "\n",
    "val_sentence_vector = [i for j, i in enumerate(val_sentence_vector) if j not in val_remove_indices]\n",
    "y_val = [i for j, i in enumerate(y_val) if j not in val_remove_indices]\n",
    "\n",
    "test_sentence_vector = [i for j, i in enumerate(test_sentence_vector) if j not in test_remove_indices]\n",
    "y_test = [i for j, i in enumerate(y_test) if j not in test_remove_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1063aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143453, 300), (143453,), (14349, 300), (14349,), (1594, 300), (1594,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentence_vector = np.array(train_sentence_vector)\n",
    "y_train = np.array(y_train)\n",
    "val_sentence_vector = np.array(val_sentence_vector)\n",
    "y_val = np.array(y_val)\n",
    "test_sentence_vector = np.array(test_sentence_vector)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "train_sentence_vector.shape, y_train.shape, val_sentence_vector.shape, y_val.shape, test_sentence_vector.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea50c83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9167886263851139 0.9209535759096612\n",
      "Confusion matrix\n",
      "[[12872    16]\n",
      " [ 1178   283]]\n",
      "f1 score 0.8911141239166358\n",
      "recall 0.9167886263851139\n",
      "precision 0.9192449263234633\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "clf.fit(train_sentence_vector, y_train)\n",
    "print(clf.score(val_sentence_vector, y_val), clf.score(test_sentence_vector, y_test))\n",
    "\n",
    "preds = clf.predict(val_sentence_vector)\n",
    "\n",
    "conf_mat = confusion_matrix(y_val, preds)\n",
    "print('Confusion matrix')\n",
    "print(conf_mat)\n",
    "print('f1 score',f1_score(y_val, preds, average='weighted', zero_division = 1))\n",
    "print('recall',recall_score(y_val, preds, average='weighted', zero_division = 1))\n",
    "print('precision',precision_score(y_val, preds, average='weighted', zero_division =1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a1968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
