{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cfcace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import collections\n",
    "import operator\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb384a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b6a462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "        'identity_hate', 'label'],\n",
       "       dtype='object'),\n",
       " (159513, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file.columns, train_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b56d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_length = 6\n",
    "new_label = []\n",
    "for each in train_file['label']:\n",
    "    temp = str(each)\n",
    "    if len(temp) != max_label_length:\n",
    "        zeros = max_label_length - len(str(each))\n",
    "        res = temp.rjust(zeros + len(temp), '0')\n",
    "        new_label.append(res)\n",
    "    else:\n",
    "        new_label.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea1ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file['label'] = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71521365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = train_file.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b7051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000000    143288\n",
       "100000      5666\n",
       "101010      3800\n",
       "101000      1758\n",
       "100010      1215\n",
       "111010       989\n",
       "101011       618\n",
       "001000       317\n",
       "000010       301\n",
       "111011       265\n",
       "001010       181\n",
       "111000       158\n",
       "100001       136\n",
       "100011       134\n",
       "101110       131\n",
       "100100       113\n",
       "111110        64\n",
       "101111        56\n",
       "000001        54\n",
       "110000        41\n",
       "101001        35\n",
       "111111        31\n",
       "000011        28\n",
       "000100        22\n",
       "001011        18\n",
       "100110        16\n",
       "110010        14\n",
       "101100        11\n",
       "110100        11\n",
       "100101         7\n",
       "110011         7\n",
       "111001         6\n",
       "111100         4\n",
       "000110         3\n",
       "100111         3\n",
       "110001         3\n",
       "001001         3\n",
       "001100         2\n",
       "001110         2\n",
       "110110         1\n",
       "110101         1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_label = train_file['label'].value_counts()\n",
    "value_counts_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba827f",
   "metadata": {},
   "source": [
    "#### some classes have only 1 data point in a class, discard them as train_test_split requires atleast 2 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a103aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159511, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_one_dp = ['110110', '110101']\n",
    "inds = train_file[ (train_file['label'] == '110110') ].index\n",
    "train_file.drop(inds , inplace=True)\n",
    "train_file.shape\n",
    "\n",
    "inds = train_file[ (train_file['label'] == '110101') ].index\n",
    "train_file.drop(inds , inplace=True)\n",
    "train_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4cbde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_file, test_size=0.1, random_state=42, stratify = train_file['label'], shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5abda2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train = train['comment_text'].reset_index(drop = True)\n",
    "y_train = train['label'].reset_index(drop = True)\n",
    "\n",
    "x_val = val['comment_text'].reset_index(drop = True)\n",
    "y_val = val['label'].reset_index(drop = True)\n",
    "\n",
    "\n",
    "del train\n",
    "del val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f79c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086a15f",
   "metadata": {},
   "source": [
    "#### download the desired model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde84f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13220a",
   "metadata": {},
   "source": [
    "#### Split the sentence, get embedding for every word, if its OOV simply skip.\n",
    "#### Lastly take the average of all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc02917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vectors(datapoint, vector_type):\n",
    "    words = datapoint.split(' ')\n",
    "    word_vectors = []\n",
    "    for each in words:\n",
    "        try:\n",
    "            word_vectors.append(fasttext_vectors[each])\n",
    "        except KeyError:\n",
    "            #if OOV then skip\n",
    "            pass\n",
    "    #take average\n",
    "    word_vectors = np.array(word_vectors)\n",
    "    \n",
    "    #if while skipping as words are OOV\n",
    "    #the list is empty then return 0\n",
    "    if vector_type == 'sent':\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.mean(word_vectors, axis = 0)\n",
    "    else:\n",
    "        if word_vectors.shape[0] == []:\n",
    "            return 0, 0\n",
    "        else:\n",
    "            return word_vectors, len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a9e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_vector = x_train.apply(sentence_vectors, vector_type = 'sent')\n",
    "val_sentence_vector = x_val.apply(sentence_vectors, vector_type = 'sent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e24bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143559,), (143559,), (15952,), (15952,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentence_vector.shape, y_train.shape, val_sentence_vector.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48083784",
   "metadata": {},
   "source": [
    "#### sentence_vectors returned 0 for the empty sentences\n",
    "#### simply delete those inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d7f4074",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_index_zerovectors(train_sentence_vector):\n",
    "    remove_indices = []\n",
    "    for index, vector in enumerate(train_sentence_vector):\n",
    "        if vector.shape == ():\n",
    "            remove_indices.append(index)\n",
    "    return remove_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d68e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_remove_indices = get_index_zerovectors(train_sentence_vector)\n",
    "val_remove_indices = get_index_zerovectors(val_sentence_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c02929d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_vector = [i for j, i in enumerate(train_sentence_vector) if j not in train_remove_indices]\n",
    "y_train = [i for j, i in enumerate(y_train) if j not in train_remove_indices]\n",
    "\n",
    "val_sentence_vector = [i for j, i in enumerate(val_sentence_vector) if j not in val_remove_indices]\n",
    "y_val = [i for j, i in enumerate(y_val) if j not in val_remove_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1063aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143454, 300), (143454,), (15940, 300), (15940,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentence_vector = np.array(train_sentence_vector)\n",
    "y_train = np.array(y_train)\n",
    "val_sentence_vector = np.array(val_sentence_vector)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "\n",
    "train_sentence_vector.shape, y_train.shape, val_sentence_vector.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428f18f",
   "metadata": {},
   "source": [
    "#### form one hot encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f289938",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "Y_train = lb.transform(y_train)\n",
    "Y_val = lb.transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfda0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=60, max_depth=3, random_state=0),\n",
    "    OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "]\n",
    "models_name = ['random forest', 'SVM - one vs rest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42f51d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest\n",
      "f1 score 0.8503644433122343\n",
      "recall 0.8984316185696362\n",
      "precision 0.9087477546760201\n",
      "accuracy 0.8984316185696362\n",
      "********************************\n",
      "SVM - one vs rest\n",
      "f1 score 0.8549527851185107\n",
      "recall 0.8999372647427855\n",
      "precision 0.8520606198146976\n",
      "accuracy 0.8999372647427855\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "trained_model = []\n",
    "for index, model in enumerate(models):\n",
    "    print(models_name[index])\n",
    "    m1 = model.fit(train_sentence_vector, Y_train)\n",
    "    trained_model.append(m1)\n",
    "    preds = m1.predict(val_sentence_vector)\n",
    "    preds = lb.inverse_transform(preds)\n",
    "    conf_mat = confusion_matrix(y_val, preds)\n",
    "    \n",
    "    print(conf_mat)\n",
    "    print('f1 score',f1_score(y_val, preds, average='weighted', zero_division = 1))\n",
    "    print('recall',recall_score(y_val, preds, average='weighted', zero_division = 1))\n",
    "    print('precision',precision_score(y_val, preds, average='weighted', zero_division =1))\n",
    "    print('accuracy',accuracy_score(y_val, preds))\n",
    "    print('********************************')\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    sns.heatmap(conf_mat, annot=True)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e720c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
